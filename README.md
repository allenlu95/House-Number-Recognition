# House-Number-Recognition
##Problem
The machine learning problem is classifying real-world images of digits. Specifically, we worked with The Street View House Numbers (SVHN) Dataset (Netzer et al.2011), http://ufldl.stanford.edu/housenumbers/, which are 32 by 32 pixels images with digits on center, taken from photos of house numbers. The challenge of this problem is to correctly classify the digits in these images with high degree of noises and distractions.
##Algorithm used
The machine learning model used is Neural Network. Specifically, we used the patternnet function provided by Matlab, which stands for Pattern Recognition Network, a particular feedforward neural network that employs Scaled Conjugate Gradient Backpropagation to
update the network layers, and Cross Entropy as the loss function. The nodes in these layers use sigmoid activation functions and the 10 nodes in the output layer each output the probability that the input image is a member of the corresponding class.
##Initial Results
The training dataset contains 73257 training images and 26032 testing images. Initially we converted the images to gray-scale and used them to train the pattern network, which achieved a 75% accuracy on the testing dataset. The pattern network ran for around 230 iterations and spent 4 minutes 40 seconds. The result showed that neural network appears to be a valid approach, but the images are too
complicated and contains too many distractions. Examples of challenges to pattern recognition include fuzzy images, digits with tilted orientation, house numbers that appear next to the true digits, and digits that are similar in color to background.
##Solutions
We worked on achieving better results with our pattern network by attempting to address the challenges above. The first observation we had was that the true digits are generally slim and occupy the center of the images, while left and right sides of images are usually noises. Our solution was to chop up both sides of the images (by repeated experimentation, we found that chopping up 6 pixels on both sides yields best results), leaving them as 32 by 20 pixels images. This measure reduced large amount of noises as well as the workload because we could now deal with fewer pixels in total. With chopping, the pattern network was able to classify in 230 iterations, 3 minutes 40 seconds, with an accuracy of 78%. We also observed that many images are hard to differentiate because they have fuzzy edges
or are of similar color to their background. We thus tried to increase the contrast of images by performing a thresholding on each of the images: take the average of an image, and every pixel lighter than that color would be assigned white, every pixel darker than that color black. As it turned out, this approach sacrificed many information about details and hence accuracy, but worked very fast because, again, it left less information to process. The best performance we got was when employing thresholding with chopping=9, where we got an accuracy of 73% in 70 iterations and 1 minute 13 seconds. Another attempt to increase contrast of images was histogram equalization. This was used to “normalize” images so that they have pixel densities evenly distributed, so as to sharpening the details without losing information in those images. Using histogram equalization to pre-process images, we found that chopping=10 yields the best result of an accuracy of 80% in 85 iterations and 2 minutes. An interesting phenomenon we observed was that the pattern network works best with chopping=6 in raw images, but as we process images with thresholding or histogram equalization before training the network, the optimal chopping size increases to 9 or 10. It appeared that chopping size determines the tradeoff between “leaving out useful details” and “including unnecessary noises”. While original neural network approach works better with more details and thus more noises, the key parameters (the threshold in thresholding and the average pixel intensity in histogram equalization) of the pre-processing steps are very sensitive to distracting noises, and thus we would be better off by chopping off more, even at the cost of losing some useful details.
